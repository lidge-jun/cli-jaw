# Phase 3 â€” Vector Embedding Memory System

> ìƒíƒœ: ğŸ“‹ ê³„íš
> ì˜ì¡´: Phase A ì™„ë£Œ (grep ê¸°ë°˜ ë©”ëª¨ë¦¬)

## ëª©í‘œ

cli-clawì˜ grep ê¸°ë°˜ ë©”ëª¨ë¦¬ë¥¼ **sqlite-vec + ë©€í‹° í”„ë¡œë°”ì´ë” ì„ë² ë”©**ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ.
ì„¤ì • ê¸°ë°˜ìœ¼ë¡œ ì„ë² ë”© í”„ë¡œë°”ì´ë”ë¥¼ ì„ íƒí•  ìˆ˜ ìˆê²Œ í•˜ê³ , ë¯¸ì„¤ì • ì‹œ ê¸°ì¡´ grepìœ¼ë¡œ graceful fallback.

---

## ì„ë² ë”© í”„ë¡œë°”ì´ë” ì˜µì…˜

| í”„ë¡œë°”ì´ë” | ëª¨ë¸ ê¸°ë³¸ê°’              | ì°¨ì› | í•„ìš” ì„¤ì •                  | ë¹„ìš©       | ë¹„ê³                              |
| ---------- | ------------------------ | ---- | -------------------------- | ---------- | -------------------------------- |
| `gemini`   | `gemini-embedding-001`   | 768  | `GEMINI_API_KEY`           | ë¬´ë£Œ~ì €ë ´  | **ê¶Œì¥**                         |
| `openai`   | `text-embedding-3-small` | 1536 | `OPENAI_API_KEY` + baseUrl | ì €ë ´       | OpenAI-compatible ì„œë²„ ì§€ì›      |
| `vertex`   | `text-embedding-005`     | 768  | GCP í”„ë¡œì íŠ¸ + ADC         | ì €ë ´, ë¹ ë¦„ | Gemini API ë³€í˜• (baseUrlë§Œ ë‹¤ë¦„) |
| `local`    | TBD                      | TBD  | node-llama-cpp ì„¤ì¹˜        | ë¬´ë£Œ       | **Phase 4** (ë¦¬ì†ŒìŠ¤ í¼)          |
| (ë¯¸ì„¤ì •)   | â€”                        | â€”    | ì—†ìŒ                       | â€”          | grep fallback                    |

### ì„¤ì • (`~/.cli-claw/settings.json`)

```json
{
  "memory": {
    "enabled": true,
    "flushEvery": 20,
    "embedding": {
      "provider": "gemini",
      "model": "gemini-embedding-001",
      "apiKey": "GEMINI_API_KEY",
      "baseUrl": ""
    }
  }
}
```

- `apiKey`: ì§ì ‘ ê°’ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì´ë¦„ (ì˜ˆ: `"GEMINI_API_KEY"` â†’ `process.env.GEMINI_API_KEY` ìë™ resolve)
- `baseUrl`: OpenAI-compatible ì„œë²„ìš© (ì˜ˆ: `http://localhost:11434/v1`)
- Vertex: `baseUrl`ì„ Vertex endpointë¡œ ì„¤ì • + GCP ADC auth

---

## ì•„í‚¤í…ì²˜

```mermaid
graph LR
    subgraph Input["ì…ë ¥"]
        FLUSH["ë©”ëª¨ë¦¬ flush<br/>(20 QAë§ˆë‹¤)"]
        SAVE["cli-claw memory save"]
        FILE["memory/*.md íŒŒì¼ ë³€ê²½"]
    end

    subgraph Embed["ì„ë² ë”© (src/embedding.js)"]
        GEM["Gemini API"]
        OAI["OpenAI API"]
        VTX["Vertex API"]
    end

    subgraph Store["ì €ì¥ (src/vector-db.js)"]
        DB["better-sqlite3<br/>+ sqlite-vec"]
        CHUNKS["chunks í…Œì´ë¸”"]
        VEC["chunks_vec ê°€ìƒ í…Œì´ë¸”"]
        FTS["chunks_fts FTS5 í…Œì´ë¸”"]
    end

    subgraph Search["ê²€ìƒ‰ (src/hybrid.js)"]
        VS["ë²¡í„° ê²€ìƒ‰<br/>cosine similarity"]
        KS["í‚¤ì›Œë“œ ê²€ìƒ‰<br/>FTS5 BM25"]
        MG["ë³‘í•© + ìŠ¤ì½”ì–´ë§"]
        TD["temporal decay"]
    end

    Input --> Embed
    Embed --> Store
    Store --> Search
    Search --> |top-K| SYS["ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸<br/>ì£¼ì…"]
```

### ì›Œí¬í”Œë¡œìš° 1: ì¸ë±ì‹± (`cli-claw memory index`)

```mermaid
sequenceDiagram
    participant U as User / CLI
    participant M as memory.js
    participant E as embedding.js
    participant V as vector-db.js
    participant API as Embedding API

    U->>M: cli-claw memory index
    M->>M: getProvider() â†’ settings.json ì½ê¸°
    M->>E: createEmbeddingProvider(config)
    E-->>M: provider {id, model, embedBatch}

    M->>M: list() â†’ memory/*.md íŒŒì¼ ëª©ë¡

    loop ê° íŒŒì¼
        M->>V: indexFile(filepath, provider)
        V->>V: SHA256 í•´ì‹œ ê³„ì‚°
        V->>V: ê¸°ì¡´ í•´ì‹œì™€ ë¹„êµ (ë³€ê²½ ì—†ìœ¼ë©´ skip)
        V->>V: chunkMarkdown(content, {tokens:200, overlap:50})
        V->>E: provider.embedBatch(chunkTexts)
        E->>API: POST /embedContent (batch)
        API-->>E: float[][] (ë²¡í„° ë°°ì—´)
        E-->>V: embeddings[]

        V->>V: BEGIN TRANSACTION
        V->>V: INSERT chunks (text + embedding JSON)
        V->>V: INSERT chunks_fts (FTS5 ì¸ë±ìŠ¤)
        V->>V: INSERT chunks_vec (sqlite-vec ë²¡í„°)
        V->>V: UPSERT files (í•´ì‹œ ê°±ì‹ )
        V->>V: COMMIT
    end

    M-->>U: âœ… Indexed 5 files, 23 chunks (gemini)
```

### ì›Œí¬í”Œë¡œìš° 2: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (`cli-claw memory search`)

```mermaid
sequenceDiagram
    participant U as User / CLI
    participant M as memory.js
    participant E as embedding.js
    participant V as vector-db.js
    participant H as hybrid.js
    participant API as Embedding API

    U->>M: cli-claw memory search "ë¸Œë¼ìš°ì € CDP"
    M->>M: getProvider()

    alt í”„ë¡œë°”ì´ë” ìˆìŒ (ë²¡í„° ê²€ìƒ‰)
        M->>E: provider.embedQuery("ë¸Œë¼ìš°ì € CDP")
        E->>API: POST /embedContent
        API-->>E: float[768]
        E-->>M: queryVec

        par ë³‘ë ¬ ê²€ìƒ‰
            M->>V: searchVector(queryVec, limit=10)
            Note over V: sqlite-vec KNN<br/>cosine distance
            V-->>M: vectorResults[]
        and
            M->>V: searchKeyword("ë¸Œë¼ìš°ì € CDP", limit=10)
            Note over V: FTS5 BM25<br/>í† í° ë§¤ì¹­
            V-->>M: keywordResults[]
        end

        M->>H: mergeHybridResults({vector, keyword})
        H->>H: ID ê¸°ì¤€ ë³‘í•©
        H->>H: score = 0.7Ã—vectorScore + 0.3Ã—textScore
        H->>H: temporal decay ì ìš© (halfLife=30ì¼)
        H->>H: score ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        H-->>M: mergedResults[]
        M-->>U: top-5 ê²°ê³¼ ì¶œë ¥

    else í”„ë¡œë°”ì´ë” ì—†ìŒ (grep fallback)
        M->>M: grepSearch("ë¸Œë¼ìš°ì € CDP")
        Note over M: grep -rni --include="*.md"<br/>~/.cli-claw/memory/
        M-->>U: grep ê²°ê³¼ ì¶œë ¥
    end
```

### ì›Œí¬í”Œë¡œìš° 3: ë©”ëª¨ë¦¬ flush â†’ ë²¡í„° ì¸ë±ì‹±

```mermaid
sequenceDiagram
    participant A as agent.js
    participant F as flush agent
    participant FS as íŒŒì¼ì‹œìŠ¤í…œ
    participant V as vector-db.js
    participant E as embedding.js

    Note over A: 20 QA í„´ ë„ë‹¬
    A->>A: triggerMemoryFlush()
    A->>F: spawnAgent(flushPrompt, {internal: true})

    F->>F: LLMì´ ëŒ€í™” ìš”ì•½ (2-5 bullet)
    F->>FS: ìš”ì•½ â†’ ~/.claude/.../memory/2026-02-24.md ì— append

    Note over A: ë‹¤ìŒ ì„¸ì…˜ ì‹œì‘ ì‹œ
    A->>A: getSystemPrompt() í˜¸ì¶œ
    A->>V: loadRecentMemories()

    alt ë²¡í„° ê²€ìƒ‰ ê°€ëŠ¥
        V->>E: ìµœê·¼ ëŒ€í™” í‚¤ì›Œë“œ â†’ embedQuery()
        E-->>V: queryVec
        V->>V: searchVector + searchKeyword
        V-->>A: "## Relevant Memories (vector search)"
    else ë²¡í„° ë¶ˆê°€
        V->>FS: flush íŒŒì¼ ì§ì ‘ ì½ê¸° (4000ì)
        V-->>A: "## Recent Session Memories"
    end

    A->>A: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë©”ëª¨ë¦¬ ì£¼ì…
```

### ì›Œí¬í”Œë¡œìš° 4: í”„ë¡œë°”ì´ë” ì„ íƒ íë¦„

```mermaid
flowchart TD
    START["settings.json ì½ê¸°"] --> CHK{"memory.embedding.provider?"}

    CHK -->|"gemini"| GEM["Gemini Provider"]
    CHK -->|"openai"| OAI["OpenAI Provider"]
    CHK -->|"vertex"| VTX["Vertex Provider"]
    CHK -->|ë¯¸ì„¤ì • / null| GREP["grep fallback"]

    GEM --> KEY_G{"apiKey í™•ì¸"}
    KEY_G -->|"GEMINI_API_KEY"| ENV_G["process.env ì—ì„œ resolve"]
    KEY_G -->|ì§ì ‘ ê°’| USE_G["ê·¸ëŒ€ë¡œ ì‚¬ìš©"]
    ENV_G --> API_G["generativelanguage.googleapis.com/v1beta"]
    USE_G --> API_G

    OAI --> KEY_O{"apiKey + baseUrl"}
    KEY_O --> API_O["baseUrl/embeddings<br/>Bearer ì¸ì¦"]

    VTX --> KEY_V{"baseUrl + GCP ADC"}
    KEY_V --> API_V["REGION-aiplatform.googleapis.com<br/>Bearer token (gcloud)"]

    API_G --> EMBED["embedQuery / embedBatch"]
    API_O --> EMBED
    API_V --> EMBED

    EMBED --> VDB["vector-db.jsì— ì €ì¥"]
    GREP --> GREP_S["execSync grep -rni"]

    style GREP fill:#f9f,stroke:#333
    style GEM fill:#4a9,stroke:#333,color:#fff
    style OAI fill:#48f,stroke:#333,color:#fff
    style VTX fill:#f80,stroke:#333,color:#fff
```

### ì›Œí¬í”Œë¡œìš° 5: Graceful Degradation (ì¥ì•  ëŒ€ì‘)

```mermaid
flowchart TD
    START["ë©”ëª¨ë¦¬ ê²€ìƒ‰ ìš”ì²­"] --> P{"í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”?"}

    P -->|ì„±ê³µ| VEC{"sqlite-vec ë¡œë“œ?"}
    P -->|ì‹¤íŒ¨: API key ì—†ìŒ| GREP["grep fallback"]
    P -->|ì‹¤íŒ¨: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜| GREP

    VEC -->|ì„±ê³µ| HYBRID["í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰<br/>Vector + FTS"]
    VEC -->|ì‹¤íŒ¨: í™•ì¥ ì—†ìŒ| FTS["FTS-only ê²€ìƒ‰<br/>í‚¤ì›Œë“œë§Œ"]

    HYBRID --> RESULT["ë³‘í•© ê²°ê³¼ ë°˜í™˜"]
    FTS --> RESULT
    GREP --> RESULT_G["grep ê²°ê³¼ ë°˜í™˜"]

    RESULT --> PROMPT["ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì£¼ì…"]
    RESULT_G --> PROMPT

    style HYBRID fill:#4a9,stroke:#333,color:#fff
    style FTS fill:#fa0,stroke:#333,color:#fff
    style GREP fill:#f9f,stroke:#333
```

---

## íŒŒì¼ë³„ êµ¬í˜„ ê³„íš

### 1. `src/embedding.js` (ì‹ ê·œ, ~130ì¤„)

ì„ë² ë”© í”„ë¡œë°”ì´ë” íŒ©í† ë¦¬. openclaw-refì˜ `embeddings.ts`, `embeddings-gemini.ts`, `embeddings-openai.ts`, `embeddings-remote-fetch.ts` ì°¸ì¡°.

```js
/**
 * @typedef {Object} EmbeddingProvider
 * @property {string} id - 'gemini' | 'openai' | 'vertex'
 * @property {string} model
 * @property {(text: string) => Promise<number[]>} embedQuery
 * @property {(texts: string[]) => Promise<number[][]>} embedBatch
 */

export function createEmbeddingProvider(config) {
  if (!config?.provider) return null;
  switch (config.provider) {
    case 'gemini':  return createGeminiProvider(config);
    case 'openai':  return createOpenAIProvider(config);
    case 'vertex':  return createVertexProvider(config);
    default: return null;
  }
}
```

#### Gemini Provider (ref: `embeddings-gemini.ts` L62-137)

```js
function createGeminiProvider(config) {
  const apiKey = resolveApiKey(config.apiKey);  // í™˜ê²½ë³€ìˆ˜ resolve
  const model = config.model || 'gemini-embedding-001';
  const baseUrl = (config.baseUrl || 'https://generativelanguage.googleapis.com/v1beta').replace(/\/+$/, '');
  const modelPath = `models/${model}`;

  return {
    id: 'gemini',
    model,
    async embedQuery(text) {
      if (!text.trim()) return [];
      const res = await fetch(`${baseUrl}/${modelPath}:embedContent?key=${apiKey}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          content: { parts: [{ text }] },
          taskType: 'RETRIEVAL_QUERY',
        }),
      });
      if (!res.ok) throw new Error(`gemini embed failed: ${res.status} ${await res.text()}`);
      const data = await res.json();
      return data.embedding?.values ?? [];
    },
    async embedBatch(texts) {
      if (!texts.length) return [];
      const requests = texts.map(text => ({
        model: modelPath,
        content: { parts: [{ text }] },
        taskType: 'RETRIEVAL_DOCUMENT',
      }));
      const res = await fetch(`${baseUrl}/${modelPath}:batchEmbedContents?key=${apiKey}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ requests }),
      });
      if (!res.ok) throw new Error(`gemini batch embed failed: ${res.status}`);
      const data = await res.json();
      return texts.map((_, i) => data.embeddings?.[i]?.values ?? []);
    },
  };
}
```

#### OpenAI-compatible Provider (ref: `embeddings-openai.ts` L30-61)

```js
function createOpenAIProvider(config) {
  const apiKey = resolveApiKey(config.apiKey);
  const model = config.model || 'text-embedding-3-small';
  const baseUrl = (config.baseUrl || 'https://api.openai.com/v1').replace(/\/+$/, '');

  const embed = async (input) => {
    const res = await fetch(`${baseUrl}/embeddings`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({ model, input }),
    });
    if (!res.ok) throw new Error(`openai embed failed: ${res.status}`);
    const data = await res.json();
    return (data.data ?? []).map(entry => entry.embedding ?? []);
  };

  return {
    id: 'openai', model,
    embedQuery: async (text) => (await embed([text]))[0] ?? [],
    embedBatch: embed,
  };
}
```

#### Vertex Provider (ref: `embeddings-gemini.ts` + Vertex baseUrl)

```js
function createVertexProvider(config) {
  // VertexëŠ” Gemini APIì™€ ë™ì¼ í¬ë§·, baseUrlë§Œ ë‹¤ë¦„
  // https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT}/locations/{REGION}/publishers/google
  // auth: GCP Application Default Credentials (gcloud auth print-access-token)
  const provider = createGeminiProvider({
    ...config,
    baseUrl: config.baseUrl || config.vertexEndpoint,
    // apiKey ëŒ€ì‹  Bearer token ì‚¬ìš©
  });
  provider.id = 'vertex';
  return provider;
}
```

> Vertex authëŠ” `gcloud auth print-access-token`ìœ¼ë¡œ Bearer í† í° íšë“.
> ë³µì¡ë„ ë•Œë¬¸ì— V1ì—ì„œëŠ” baseUrl + Bearer í† í° ì§ì ‘ ì„¤ì • ë°©ì‹ìœ¼ë¡œ êµ¬í˜„.

#### ìœ í‹¸ë¦¬í‹°

```js
function resolveApiKey(raw) {
  if (!raw) return process.env.GEMINI_API_KEY || process.env.OPENAI_API_KEY || '';
  // í™˜ê²½ë³€ìˆ˜ ì´ë¦„ì´ë©´ resolve
  if (/^[A-Z_]+$/.test(raw) && process.env[raw]) return process.env[raw];
  return raw;
}
```

---

### 2. `src/vector-db.js` (ì‹ ê·œ, ~220ì¤„)

better-sqlite3 + sqlite-vec ê¸°ë°˜. openclaw-refì˜ `memory-schema.ts`, `sqlite-vec.ts`, `manager-sync-ops.ts`, `internal.ts` ì°¸ì¡°.

#### DB ì´ˆê¸°í™”

```js
import Database from 'better-sqlite3';
import { join } from 'path';
import { CLAW_HOME } from './config.js';
import crypto from 'crypto';

const DB_PATH = join(CLAW_HOME, 'memory', 'vector.db');
let db = null;
let vecLoaded = false;
let vecDims = null;

export function getVectorDB() {
  if (db) return db;
  db = new Database(DB_PATH);

  // sqlite-vec í™•ì¥ ë¡œë“œ
  try {
    const sqliteVec = await import('sqlite-vec');
    sqliteVec.load(db);
    vecLoaded = true;
  } catch (e) {
    console.log('[vector-db] sqlite-vec unavailable, FTS-only mode:', e.message);
  }

  // ìŠ¤í‚¤ë§ˆ ìƒì„± (ref: memory-schema.ts)
  db.exec(`
    CREATE TABLE IF NOT EXISTS files (
      path TEXT PRIMARY KEY,
      hash TEXT NOT NULL,
      mtime INTEGER NOT NULL,
      size INTEGER NOT NULL
    );
    CREATE TABLE IF NOT EXISTS chunks (
      id TEXT PRIMARY KEY,
      path TEXT NOT NULL,
      start_line INTEGER NOT NULL,
      end_line INTEGER NOT NULL,
      hash TEXT NOT NULL,
      model TEXT NOT NULL,
      text TEXT NOT NULL,
      embedding TEXT NOT NULL,
      updated_at INTEGER NOT NULL
    );
    CREATE INDEX IF NOT EXISTS idx_chunks_path ON chunks(path);
  `);

  // FTS5
  try {
    db.exec(`
      CREATE VIRTUAL TABLE IF NOT EXISTS chunks_fts USING fts5(
        text, id UNINDEXED, path UNINDEXED
      );
    `);
  } catch (e) {
    console.log('[vector-db] FTS5 unavailable:', e.message);
  }

  return db;
}
```

#### ë²¡í„° í…Œì´ë¸” (ë™ì  ì°¨ì›)

```js
// ref: manager-sync-ops.ts L209-222
export function ensureVectorTable(dimensions) {
  if (!vecLoaded || vecDims === dimensions) return;
  if (vecDims && vecDims !== dimensions) {
    db.exec('DROP TABLE IF EXISTS chunks_vec');
  }
  db.exec(`
    CREATE VIRTUAL TABLE IF NOT EXISTS chunks_vec USING vec0(
      id TEXT PRIMARY KEY,
      embedding FLOAT[${dimensions}]
    );
  `);
  vecDims = dimensions;
}
```

#### ì²­í‚¹ (ref: `internal.ts` L184-265)

```js
export function chunkMarkdown(content, { tokens = 200, overlap = 50 } = {}) {
  const lines = content.split('\n');
  const maxChars = Math.max(32, tokens * 4);
  const overlapChars = Math.max(0, overlap * 4);
  const chunks = [];
  let current = [], currentChars = 0;

  const flush = () => {
    if (!current.length) return;
    const text = current.map(e => e.line).join('\n');
    chunks.push({
      startLine: current[0].lineNo,
      endLine: current[current.length - 1].lineNo,
      text,
      hash: crypto.createHash('sha256').update(text).digest('hex'),
    });
  };

  const carryOverlap = () => {
    if (overlapChars <= 0) { current = []; currentChars = 0; return; }
    let acc = 0;
    const kept = [];
    for (let i = current.length - 1; i >= 0; i--) {
      acc += current[i].line.length + 1;
      kept.unshift(current[i]);
      if (acc >= overlapChars) break;
    }
    current = kept;
    currentChars = kept.reduce((s, e) => s + e.line.length + 1, 0);
  };

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i] ?? '';
    const lineSize = line.length + 1;
    if (currentChars + lineSize > maxChars && current.length > 0) {
      flush();
      carryOverlap();
    }
    current.push({ line, lineNo: i + 1 });
    currentChars += lineSize;
  }
  flush();
  return chunks;
}
```

#### íŒŒì¼ ì¸ë±ì‹±

```js
export async function indexFile(filepath, provider) {
  const content = fs.readFileSync(filepath, 'utf8');
  const relPath = path.relative(join(CLAW_HOME, 'memory'), filepath);
  const hash = crypto.createHash('sha256').update(content).digest('hex');

  // ë³€ê²½ ì—†ìœ¼ë©´ ìŠ¤í‚µ
  const existing = db.prepare('SELECT hash FROM files WHERE path = ?').get(relPath);
  if (existing?.hash === hash) return { skipped: true };

  const chunks = chunkMarkdown(content);
  const texts = chunks.map(c => c.text);
  const embeddings = await provider.embedBatch(texts);

  // íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì¼ê´„ ì €ì¥
  const tx = db.transaction(() => {
    // ê¸°ì¡´ ì²­í¬ ì‚­ì œ
    db.prepare('DELETE FROM chunks WHERE path = ?').run(relPath);
    try { db.prepare('DELETE FROM chunks_fts WHERE path = ?').run(relPath); } catch {}
    try { db.prepare('DELETE FROM chunks_vec WHERE id IN (SELECT id FROM chunks WHERE path = ?)').run(relPath); } catch {}

    // íŒŒì¼ ë ˆì½”ë“œ ê°±ì‹ 
    db.prepare('INSERT OR REPLACE INTO files (path, hash, mtime, size) VALUES (?, ?, ?, ?)')
      .run(relPath, hash, Date.now(), content.length);

    // ì²­í¬ + ì„ë² ë”© ì €ì¥
    const insertChunk = db.prepare(
      'INSERT INTO chunks (id, path, start_line, end_line, hash, model, text, embedding, updated_at) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)'
    );
    const insertFts = db.prepare('INSERT INTO chunks_fts (text, id, path) VALUES (?, ?, ?)');

    for (let i = 0; i < chunks.length; i++) {
      const c = chunks[i];
      const vec = embeddings[i];
      const id = `${relPath}:${c.startLine}-${c.endLine}`;
      insertChunk.run(id, relPath, c.startLine, c.endLine, c.hash, provider.model, c.text, JSON.stringify(vec), Date.now());
      try { insertFts.run(c.text, id, relPath); } catch {}

      // sqlite-vec ì €ì¥
      if (vecLoaded && vec.length > 0) {
        ensureVectorTable(vec.length);
        try {
          db.prepare('INSERT OR REPLACE INTO chunks_vec (id, embedding) VALUES (?, ?)').run(id, JSON.stringify(vec));
        } catch {}
      }
    }
  });
  tx();
  return { chunks: chunks.length, path: relPath };
}
```

#### ê²€ìƒ‰ â€” ë²¡í„°

```js
// ref: internal.ts L297-316 (cosine similarity)
export function cosineSimilarity(a, b) {
  if (!a.length || !b.length) return 0;
  const len = Math.min(a.length, b.length);
  let dot = 0, normA = 0, normB = 0;
  for (let i = 0; i < len; i++) {
    dot += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  return normA && normB ? dot / (Math.sqrt(normA) * Math.sqrt(normB)) : 0;
}

export function searchVector(queryVec, limit = 10) {
  if (!vecLoaded) return [];
  // sqlite-vec KNN ê²€ìƒ‰
  const rows = db.prepare(`
    SELECT v.id, v.distance, c.path, c.start_line, c.end_line, c.text
    FROM chunks_vec v
    JOIN chunks c ON c.id = v.id
    WHERE v.embedding MATCH ?
    ORDER BY v.distance
    LIMIT ?
  `).all(JSON.stringify(queryVec), limit);

  return rows.map(r => ({
    id: r.id, path: r.path,
    startLine: r.start_line, endLine: r.end_line,
    snippet: r.text.slice(0, 500),
    vectorScore: 1 / (1 + r.distance),  // distance â†’ similarity
  }));
}
```

#### ê²€ìƒ‰ â€” FTS5 í‚¤ì›Œë“œ

```js
// ref: hybrid.ts L33-49
export function searchKeyword(query, limit = 10) {
  const tokens = query.match(/[\p{L}\p{N}_]+/gu)?.map(t => t.trim()).filter(Boolean) ?? [];
  if (!tokens.length) return [];
  const ftsQuery = tokens.map(t => `"${t.replace(/"/g, '')}"`).join(' AND ');

  try {
    const rows = db.prepare(`
      SELECT id, path, rank, text
      FROM chunks_fts
      WHERE chunks_fts MATCH ?
      ORDER BY rank
      LIMIT ?
    `).all(ftsQuery, limit);

    return rows.map(r => ({
      id: r.id, path: r.path,
      snippet: r.text.slice(0, 500),
      textScore: 1 / (1 + Math.max(0, r.rank)),  // BM25 rank â†’ score
    }));
  } catch { return []; }
}
```

---

### 3. `src/hybrid.js` (ì‹ ê·œ, ~80ì¤„)

FTS + Vector ê²°ê³¼ ë³‘í•©. openclaw-refì˜ `hybrid.ts`ì™€ `temporal-decay.ts` ê°„ì†Œí™”.

```js
// ref: hybrid.ts L51-149

const DAY_MS = 86400000;

/**
 * í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ë³‘í•©
 * @param {Object} params
 * @param {Array} params.vector - [{id, path, snippet, vectorScore, startLine, endLine}]
 * @param {Array} params.keyword - [{id, path, snippet, textScore}]
 * @param {number} params.vectorWeight - ê¸°ë³¸ 0.7
 * @param {number} params.textWeight - ê¸°ë³¸ 0.3
 * @param {number} params.halfLifeDays - temporal decay ë°˜ê°ê¸° (0ì´ë©´ ë¹„í™œì„±)
 */
export function mergeHybridResults({
  vector = [], keyword = [],
  vectorWeight = 0.7, textWeight = 0.3,
  halfLifeDays = 30,
}) {
  const byId = new Map();

  for (const r of vector) {
    byId.set(r.id, { ...r, vectorScore: r.vectorScore, textScore: 0 });
  }
  for (const r of keyword) {
    const existing = byId.get(r.id);
    if (existing) {
      existing.textScore = r.textScore;
      if (r.snippet?.length > 0) existing.snippet = r.snippet;
    } else {
      byId.set(r.id, { ...r, vectorScore: 0, textScore: r.textScore });
    }
  }

  let results = Array.from(byId.values()).map(entry => ({
    ...entry,
    score: vectorWeight * entry.vectorScore + textWeight * entry.textScore,
  }));

  // Temporal decay (ref: temporal-decay.ts L24-34)
  if (halfLifeDays > 0) {
    const lambda = Math.LN2 / halfLifeDays;
    const now = Date.now();
    results = results.map(r => {
      const dateMatch = r.path?.match(/(\d{4}-\d{2}-\d{2})/);
      if (!dateMatch) return r;  // ë‚ ì§œ ì—†ëŠ” íŒŒì¼ì€ evergreen
      const fileDate = new Date(dateMatch[1]).getTime();
      const ageDays = Math.max(0, (now - fileDate) / DAY_MS);
      return { ...r, score: r.score * Math.exp(-lambda * ageDays) };
    });
  }

  return results.sort((a, b) => b.score - a.score);
}
```

> MMRì€ ì œì™¸ â€” ë©”ëª¨ë¦¬ ê·œëª¨ê°€ ì‘ì•„ì„œ ë‹¤ì–‘ì„± ë¬¸ì œ ì—†ìŒ (í•„ìš”ì‹œ ì¶”í›„ ì¶”ê°€)

---

### 4. `src/memory.js` ìˆ˜ì • (+50ì¤„)

```diff
+ import { createEmbeddingProvider } from './embedding.js';
+ import * as vectorDB from './vector-db.js';
+ import { mergeHybridResults } from './hybrid.js';

+ let _provider = null;
+ let _providerInitialized = false;

+ function getProvider() {
+   if (_providerInitialized) return _provider;
+   _providerInitialized = true;
+   const embConfig = settings.memory?.embedding;
+   _provider = createEmbeddingProvider(embConfig);
+   if (_provider) console.log(`[memory] embedding: ${_provider.id}/${_provider.model}`);
+   else console.log('[memory] embedding: disabled (grep fallback)');
+   return _provider;
+ }

  export function search(query) {
+   const provider = getProvider();
+   if (provider) return hybridSearch(query, provider);
    // ê¸°ì¡´ grep (fallback)
    return grepSearch(query);
  }

+ export async function hybridSearch(query, provider, opts = {}) {
+   const db = vectorDB.getVectorDB();
+   const queryVec = await provider.embedQuery(query);
+   const vecResults = vectorDB.searchVector(queryVec, opts.limit || 10);
+   const kwResults = vectorDB.searchKeyword(query, opts.limit || 10);
+   const merged = mergeHybridResults({
+     vector: vecResults, keyword: kwResults,
+     vectorWeight: 0.7, textWeight: 0.3, halfLifeDays: 30,
+   });
+   return merged.slice(0, opts.limit || 5);
+ }

+ export async function indexAllMemoryFiles() {
+   const provider = getProvider();
+   if (!provider) throw new Error('Embedding provider not configured');
+   vectorDB.getVectorDB();  // DB ì´ˆê¸°í™”
+   const files = list();
+   let total = 0;
+   for (const f of files) {
+     const result = await vectorDB.indexFile(
+       join(MEMORY_DIR, f.path), provider
+     );
+     if (!result.skipped) total += result.chunks;
+   }
+   return { files: files.length, chunks: total, provider: provider.id };
+ }
```

---

### 5. `bin/commands/memory.js` ìˆ˜ì • (+30ì¤„)

```diff
+ case 'index':
+   const { indexAllMemoryFiles } = await import('../../src/memory.js');
+   const result = await indexAllMemoryFiles();
+   console.log(`âœ… Indexed ${result.files} files, ${result.chunks} chunks (${result.provider})`);
+   break;

+ case 'status':
+   const { settings } = await import('../../src/config.js');
+   const emb = settings.memory?.embedding;
+   if (!emb?.provider) {
+     console.log('Embedding: disabled (grep fallback)');
+   } else {
+     console.log(`Provider: ${emb.provider}`);
+     console.log(`Model: ${emb.model || '(default)'}`);
+     console.log(`API Key: ${emb.apiKey ? '***configured***' : 'missing'}`);
+   }
+   break;
```

---

### 6. `src/prompt.js` ìˆ˜ì • (+20ì¤„)

`loadRecentMemories()` ê°œì„  â€” ì„ë² ë”©ì´ ê°€ëŠ¥í•˜ë©´ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë©”ëª¨ë¦¬ ì£¼ì…:

```diff
  export function loadRecentMemories() {
+   // ë²¡í„° ê²€ìƒ‰ì´ ê°€ëŠ¥í•˜ë©´ ìµœê·¼ ëŒ€í™” í‚¤ì›Œë“œë¡œ ê´€ë ¨ ë©”ëª¨ë¦¬ ê²€ìƒ‰
+   try {
+     const { getProvider, hybridSearch } = require('./memory.js');
+     if (getProvider()) {
+       // ìµœê·¼ ëŒ€í™”ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ â†’ ë²¡í„° ê²€ìƒ‰
+       const recent = getRecentMessages?.all?.(3)?.reverse() ?? [];
+       const keywords = recent.map(m => m.content).join(' ').slice(0, 500);
+       if (keywords.trim()) {
+         const results = await hybridSearch(keywords, getProvider(), { limit: 5 });
+         if (results.length) {
+           const entries = results.map(r => `- [${r.path}] ${r.snippet.split('\n')[0]}`);
+           return '\n\n---\n## Relevant Memories (vector search)\n' + entries.join('\n');
+         }
+       }
+     }
+   } catch {}
    // fallback: ê¸°ì¡´ íŒŒì¼ ê¸°ë°˜
    try { ... }
  }
```

---

### 7. `package.json` ìˆ˜ì •

```diff
  "dependencies": {
+   "sqlite-vec": "^0.1.6"
  }
```

> `better-sqlite3`ëŠ” ì´ë¯¸ ìˆìŒ. `sqlite-vec`ë§Œ ì¶”ê°€ (~2MB prebuilt ë°”ì´ë„ˆë¦¬).
> `node:sqlite`ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ â€” ë°°í¬ìš©ìœ¼ë¡œ Node.js ë²„ì „ ì œì•½ì„ í”¼í•˜ê¸° ìœ„í•´ `better-sqlite3` ìœ ì§€.

---

## íŒŒì¼ ìš”ì•½

| íŒŒì¼                     | ì•¡ì…˜   | ì¤„ ìˆ˜ | ì°¸ì¡° (openclaw-ref)                                                       |
| ------------------------ | ------ | ----- | ------------------------------------------------------------------------- |
| `src/embedding.js`       | NEW    | ~130  | `embeddings.ts`, `embeddings-gemini.ts`, `embeddings-openai.ts`           |
| `src/vector-db.js`       | NEW    | ~220  | `memory-schema.ts`, `sqlite-vec.ts`, `internal.ts`, `manager-sync-ops.ts` |
| `src/hybrid.js`          | NEW    | ~80   | `hybrid.ts`, `temporal-decay.ts`                                          |
| `src/memory.js`          | MODIFY | +50   | `manager.ts` search integration                                           |
| `bin/commands/memory.js` | MODIFY | +30   | CLI commands                                                              |
| `src/prompt.js`          | MODIFY | +20   | prompt injection                                                          |
| `package.json`           | MODIFY | +1    | `sqlite-vec` dependency                                                   |

**ì´ ~530ì¤„ ì‹ ê·œ ì½”ë“œ, 3ê°œ ì‹ ê·œ íŒŒì¼, 1ê°œ npm ì˜ì¡´ì„± ì¶”ê°€**

---

## êµ¬í˜„ ìˆœì„œ

```
1. package.jsonì— sqlite-vec ì¶”ê°€ + npm install
2. src/embedding.js â€” í”„ë¡œë°”ì´ë” íŒ©í† ë¦¬ (gemini ë¨¼ì €)
3. src/vector-db.js â€” DB ì´ˆê¸°í™” + ì²­í‚¹ + ì¸ë±ì‹±
4. src/hybrid.js â€” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë³‘í•©
5. src/memory.js â€” ê¸°ì¡´ search()ì— ë²¡í„° ê²€ìƒ‰ í†µí•©
6. bin/commands/memory.js â€” index/status ì»¤ë§¨ë“œ
7. src/prompt.js â€” ë²¡í„° ê¸°ë°˜ ë©”ëª¨ë¦¬ í”„ë¡¬í”„íŠ¸ ì£¼ì…
```

---

## í…ŒìŠ¤íŠ¸ ê³„íš

### ìˆ˜ë™ í…ŒìŠ¤íŠ¸

```bash
# 1. ì„ë² ë”© ìƒíƒœ í™•ì¸
cli-claw memory status
# â†’ Provider: gemini, Model: gemini-embedding-001

# 2. ì „ì²´ ì¸ë±ì‹±
cli-claw memory index
# â†’ âœ… Indexed 5 files, 23 chunks (gemini)

# 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
cli-claw memory search "ë¸Œë¼ìš°ì € ì„¤ì •"
# â†’ ë²¡í„° + FTS ê²°ê³¼, ìŠ¤ì½”ì–´ í¬í•¨

# 4. grep fallback (ì„ë² ë”© ë¯¸ì„¤ì •)
# settings.jsonì—ì„œ embedding ì œê±° í›„
cli-claw memory search "ë¸Œë¼ìš°ì €"
# â†’ ê¸°ì¡´ grep ê²°ê³¼ ë™ì¼
```

---

## í–¥í›„ ê³ ë„í™” (Phase 4+)

- [ ] `local` í”„ë¡œë°”ì´ë” (node-llama-cpp + embeddinggemma)
- [ ] MMR re-ranking (ê²€ìƒ‰ ë‹¤ì–‘ì„±)
- [ ] íŒŒì¼ ê°ì‹œ (chokidar) â€” ë©”ëª¨ë¦¬ íŒŒì¼ ë³€ê²½ ì‹œ ìë™ ì¬ì¸ë±ì‹±
- [ ] ì„ë² ë”© ìºì‹œ (`embedding_cache` í…Œì´ë¸”) â€” ë™ì¼ í…ìŠ¤íŠ¸ ì¬ì„ë² ë”© ë°©ì§€
- [ ] ì„¸ì…˜ ëŒ€í™” ì¸ë±ì‹± â€” SQLite messages í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì„ë² ë”©
